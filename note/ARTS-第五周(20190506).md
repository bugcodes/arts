## Algorithm

> [242题-Valid Anagram](<https://leetcode.com/problems/valid-anagram/>)

## 解题思路1 - 排序

字谜t是通过对字符串s进行重排排序产生的，所以对两个字符串排序会得到两个相同的字符串。此外，如果s和t长度不相同，那么t肯定不是s的字谜。

```
public boolean isAnagram(String s ,String t){
    if(s.length() != t.length()){
        return false;
    }
    char[] str1 = s.toCharArray();
    char[] str2 = t.toCharArray();
    Arrays.sort(str1);
    Arrays.sort(str2);
    return Arrays.equals(str1,str2);
}
```

### 复杂度分析

时间复杂度：O(nlogn)，假设n是字符串的长度，排序需要O(nlogn)的时间复杂度，比较两个字符串需要O(n)。大规模情况下排序时间占主导地位。

空间复杂度：O(1)，空间依赖于算法的实现。如果使用堆，通常需要O(1)的空间复杂度。但是在java中，因为toCharArray()会复制字符串产生副本，会用到O(n)的空间复杂度。但是算法中我们会忽略这种语言的差异。

## 解题思路2 - 哈希表

检查字符串t是否是s的重排序，我们可以计算两个字符串中每个字母出现的次数然后再比对。由于两个字符串仅仅包含来自a~z的字母。一个大小为26的简单计数表就够了。

我们不需要产生两个计数表然后对它们进行比对，我们可以在一个计数表里针对字符串s的每个字符数量进行累加，同时针对字符串t的每个字符数量进行递减，最后我们检查计数表是否为0。

```
public boolean isAnagram(String s, String t){
    if(s.length() != t.length()){
        return false;
    }
    int[] counter = new int[26]
    for(int i = 0 ; i < s.length() ; i++){
        counter[s.charAt(i) - 'a']++;
        counter[t.charAt(i) - 'a']--;
    }
    for(int count : counter){
        if(count != 0){
            return false;
        }
    }
    return true;
}
```

或者，我们可以先增加s的计数表，然后再减去t的计数表。在任何一步，如果t的某个字符的计数值小于0，那么说明t中的某个字符在s中不存在，我们就可以立即返回。

```
public boolean isAnagram(String s ,String t){
    if(s.length() != t.length()){
        return false;
    }
    int[] table = new int[26];
    for(int i = 0; i < s.length();i++){
        table[s.charAt(i) - 'a']++;
    }
    for(int i = 0; i < t.length();i++){
        table[t.charAt(i) - 'a']--;
        if(table[t.charAt(i) - 'a'] < 0){
            return false;
        }
    }
    return true;
}
```

### 复杂度分析

时间复杂度：O(n)，假设字符串的长度为n，访问计数器表是一个恒定的时间操作。

空间复杂度：O(1)，无论n有多大，表的大小都保持不变，它是一个常数。

## 如果输入包含unicode字符怎么办，如何解决

### 解决办法

用一个hash表来代替这个固定长度的计数器表。如果要分配一个大数组来适配整个unicode字符范围，这可能会超过100万。**哈希表是一个更通用的解决方案，可以适应任何范围的字符。**

## Review

> [Golang指南：顶级Golang框架，IDE和工具列表](<https://medium.com/@quintinglvr/golang-guide-a-list-of-top-golang-frameworks-ides-tools-e7c7866e96c9>)

#### Golang框架

**Revel**，一个高生产力的 Go 语言 Web 框架。

**Beego**，一个成熟的MVC框架，拥有自己的日志库，ORM和Web框架。

**Martini**，一个轻量级但是功能强大的框架，为编写模块化Web应用程序和服务而生。

**Gin Gonic**，一个简约的框架，只包含重要的库和功能，非常适合开发高性能的REST APIS，比Martini快40倍。

**Goji**，一个轻量级和快速的Web框架，可组合，支持websocket，可用于生产环境并提供数十亿的请求。

#### IDE ：Goland、Visual Studio Code、LiteIDE、Wide(中国)、Eclipse with GoClipse、Sublime Text with GoSublime

## Tip

工作中如果业务数据量很小的情况下，有多问题无法暴露出来，所谓高并发，数据库索引优化都无从谈起。有时候需要自己创造条件去学习，下面分享一段**MySQL快速生成百万数据**的方法，工作之余可以自己玩一下

```
CREATE FUNCTION `rand_string`(n INT) RETURNS varchar(255) CHARSET latin1   ##定义一个函数，用来生成随机字符串
BEGIN
DECLARE chars_str varchar(100) DEFAULT 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789';
DECLARE return_str varchar(255) DEFAULT '' ;
DECLARE i INT DEFAULT 0;
WHILE i < n DO
SET return_str = concat(return_str,substring(chars_str , FLOOR(1 + RAND()*62 ),1));
SET i = i +1;
END WHILE;
RETURN return_str;
END;


delimiter $$    ##存储过程开始
DROP PROCEDURE IF EXISTS test_batch_insert;   ##如果已存在名称为test_batch_insert的存储过程，则先删除
CREATE PROCEDURE test_batch_insert()   ##创建名称为test_batch_insert的存储过程
BEGIN   ## 开始标识
DECLARE i INT;  ##定义了一个整型的变量i
SET i=1;  ## 初始化i等于1
WHILE i < 500 DO  ## 这是一个循环，执行500次，
		INSERT INTO user(username_,id_,password_) VALUES(i+95500000,rand_string(15),rand_string(15));  ## 向user表中插入500条数据
SET i=i+1; ## i累加
END WHILE;
END $$
delimiter ;


CALL test_batch_insert(); ## 调用该存储过程
```

## Share

# 常见性能优化策略分类

## 代码

之所以把代码放到第一位，是因为这一点最容易引起技术人员的忽视。很多技术人员拿到一个性能优化的需求以后，言必称缓存、异步、JVM等。实际上，第一步就应该是分析相关的代码，找出相应的瓶颈，再来考虑具体的优化策略。有一些性能问题，完全是由于代码写的不合理，通过直接修改一下代码就能解决问题的，比如**for循环次数过多、作了很多无谓的条件判断、相同逻辑重复多次**等。

## 数据库

数据库的调优，总的来说分为以下三部分：

### SQL调优

这是**最常用、每一个技术人员都应该掌握基本的SQL调优手段（包括方法、工具、辅助系统等）**。这里以MySQL为例，最常见的方式是，由**自带的慢查询日志或者开源的慢查询系统**定位到具体的出问题的SQL，然后使用**explain、profile**等工具来逐步调优，最后经过测试达到效果后上线。这方面的细节，可以参考[MySQL索引原理及慢查询优化](http://tech.meituan.com/mysql-index.html)。

### 架构层面的调优

这一类调优包括**读写分离、多从库负载均衡、水平和垂直分库分表**等方面，一般需要的改动较大，但是频率没有SQL调优高，而且一般需要DBA来配合参与。那么什么时候需要做这些事情？我们可以通过内部监控报警系统（比如Zabbix），定期跟踪一些指标数据是否达到瓶颈，一旦达到瓶颈或者警戒值，就需要考虑这些事情。通常，DBA也会定期监控这些指标值。

### 连接池调优

我们的应用为了实现数据库连接的高效获取、对数据库连接的限流等目的，通常会采用连接池类的方案，即每一个应用节点都管理了一个到各个数据库的连接池。随着业务访问量或者数据量的增长，原有的连接池参数可能不能很好地满足需求，这个时候就需要结合**当前使用连接池的原理、具体的连接池监控数据和当前的业务量**作一个综合的判断，通过反复的几次调试得到最终的调优参数。

## 缓存

### 分类

本地缓存（HashMap/ConcurrentHashMap、Ehcache、Guava Cache等），缓存服务（Redis/Tair/Memcache等）。

### 使用场景

什么情况适合用缓存？考虑以下两种场景：

- 短时间内相同数据重复查询多次且数据更新不频繁，这个时候可以选择先从缓存查询，查询不到再从数据库加载并回设到缓存的方式。此种场景较适合用单机缓存。
- 高并发查询热点数据，后端数据库不堪重负，可以用缓存来扛。

### 选型考虑

- 如果数据量小，并且不会频繁地增长又清空（这会导致频繁地垃圾回收），那么可以选择本地缓存。具体的话，如果需要一些策略的支持（比如缓存满的逐出策略），可以考虑Ehcache；如不需要，可以考虑HashMap；如需要考虑多线程并发的场景，可以考虑ConcurentHashMap。
- 其他情况，可以考虑缓存服务。目前从资源的投入度、可运维性、是否能动态扩容以及配套设施来考虑，我们优先考虑Tair。除非目前Tair还不能支持的场合（比如分布式锁、Hash类型的value），我们考虑用Redis。

### 设计关键点

#### 什么时候更新缓存？如何保障更新的可靠性和实时性？

更新缓存的策略，需要具体问题具体分析。这里以门店POI的缓存数据为例，来说明一下缓存服务型的缓存更新策略是怎样的？目前约10万个POI数据采用了Tair作为缓存服务，具体更新的策略有两个：

- 接收门店变更的消息，准实时更新。
- 给每一个POI缓存数据设置5分钟的过期时间，过期后从DB加载再回设到DB。这个策略是对第一个策略的有力补充，解决了手动变更DB不发消息、接消息更新程序临时出错等问题导致的第一个策略失效的问题。通过这种双保险机制，有效地保证了POI缓存数据的可靠性和实时性。

#### 缓存是否会满，缓存满了怎么办？

对于一个缓存服务，理论上来说，随着缓存数据的日益增多，在容量有限的情况下，缓存肯定有一天会满的。如何应对？
① 给缓存服务，选择合适的缓存逐出算法，比如最常见的LRU。
② 针对当前设置的容量，设置适当的警戒值，比如10G的缓存，当缓存数据达到8G的时候，就开始发出报警，提前排查问题或者扩容。
③ 给一些没有必要长期保存的key，尽量设置过期时间。

#### 缓存是否允许丢失？丢失了怎么办？

根据业务场景判断，是否允许丢失。如果不允许，就需要带持久化功能的缓存服务来支持，比如Redis或者Tair。更细节的话，可以根据业务对丢失时间的容忍度，还可以选择更具体的持久化策略，比如Redis的RDB或者AOF。

#### 缓存被**“击穿”**问题

对于一些设置了过期时间的key，如果这些key可能会在某些时间点被超高并发地访问，是一种非常“热点”的数据。这个时候，需要考虑另外一个问题：缓存被**“击穿”**的问题。

- 概念：缓存在某个时间点过期的时候，恰好在这个时间点对这个Key有大量的并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。

- 如何解决：业界比较常用的做法，是使用mutex。简单地来说，就是在缓存失效的时候（判断拿出来的值为空），不是立即去load db，而是先使用缓存工具的某些带成功操作返回值的操作（比如Redis的SETNX或者Memcache的ADD）去set一个mutex key，当操作返回成功时，再进行load db的操作并回设缓存；否则，就重试整个get缓存的方法。类似下面的代码：

  ```
    public String get(key) {
        String value = redis.get(key);
        if (value == null) { //代表缓存值过期
            //设置3min的超时，防止del操作失败的时候，下次缓存过期一直不能load db
            if (redis.setnx(key_mutex, 1, 3 * 60) == 1) {  //代表设置成功
                 value = db.get(key);
                        redis.set(key, value, expire_secs);
                        redis.del(key_mutex);
                } else {  //这个时候代表同时候的其他线程已经load db并回设到缓存了，这时候重试获取缓存值即可
                        sleep(50);
                        get(key);  //重试
                }
            } else {
                return value;      
            }
    }
  ```

## 异步

### 使用场景

针对某些客户端的请求，在服务端可能需要针对这些请求做一些附属的事情，这些事情其实用户并不关心或者用户不需要立即拿到这些事情的处理结果，这种情况就比较适合用异步的方式处理这些事情。

### 作用

- 缩短接口响应时间，使用户的请求快速返回，用户体验更好。
- 避免线程长时间处于运行状态，这样会引起服务线程池的可用线程长时间不够用，进而引起线程池任务队列长度增大，从而阻塞更多请求任务，使得更多请求得不到技术处理。
- 线程长时间处于运行状态，可能还会引起系统Load、CPU使用率、机器整体性能下降等一系列问题，甚至引发雪崩。异步的思路可以在不增加机器数和CPU数的情况下，有效解决这个问题。

### 常见做法

**一种做法**，是额外开辟线程，这里可以采用额外开辟一个线程或者使用线程池的做法，在IO线程（处理请求响应）之外的线程来处理相应的任务，在IO线程中让response先返回。

如果异步线程处理的任务设计的数据量非常巨大，那么可以引入阻塞队列BlockingQueue作进一步的优化。具体做法是让一批异步线程不断地往阻塞队列里扔数据，然后额外起一个处理线程，循环批量从队列里拿预设大小的一批数据，来进行批处理（比如发一个批量的远程服务请求），这样进一步提高了性能。

**另一种做法**，是使用消息队列（MQ）中间件服务，MQ天生就是异步的。一些额外的任务，可能不需要我这个系统来处理，但是需要其他系统来处理。这个时候可以先把它封装成一个消息，扔到消息队列里面，通过消息中间件的可靠性保证把消息投递到关心它的系统，然后让这个系统来做相应的处理。

比如C端在完成一个提单动作以后，可能需要其它端做一系列的事情，但是这些事情的结果不会立刻对C端用户产生影响，那么就可以先把C端下单的请求响应先返回给用户，返回之前往MQ中发一个消息即可。而且这些事情理应不是C端的负责范围，所以这个时候用MQ的方式，来解决这个问题最合适。